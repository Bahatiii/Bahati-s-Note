# Touch in the Wild: Learning Fine-Grained Manipulation with a Portable Visuo-Tactile Gripper
https://openreview.net/pdf/55617f304c7c239e88b83215b4fb54d079a4379c.pdf

## 解决了什么问题
现有的gripper大多缺乏触觉传感，严重依赖视觉，并且难以在现实世界的环境中同步、大规模的收集高质量视觉和触觉数据。

## 提出
通过开发一个便携式、轻量化且集成触觉传感器的gripper，在野外环境下大规模收集同步的视觉-触觉数据，可以训练出一个多模态表征学习框架。这个框架能够融合视觉的全局语义和触觉的局部高分辨率接触信息，从而极大地提高机器人策略学习的效率、准确性和在扰动下的鲁棒性，特别是在精细操作任务中。

## 怎么解决
1. 硬件解决方案：便携式视觉-触觉抓手
 * 抓手设计： 设计了一个轻量化、便携式的手持抓手，便于人类操作员在各种场景中进行演示。
 * 传感器集成： 将柔性压阻式触觉传感器集成到抓手的软性、适应性强的指尖上。这些传感器总厚度不到 $1\text{mm}$，能够弯曲并提供高频的压力数据。
 * 同步数据采集： 系统配备了鱼眼 RGB 摄像头和触觉传感器阵列，确保在整个演示过程中，视觉和触觉数据被精确地同步记录。
2. 学习框架：跨模态表征学习
 * 预训练目标： 提出了一种跨模态表征学习框架来融合视觉和触觉信号
 * 模型在一个大型的图像-触觉对语料库上进行预训练
   * 核心任务： 模型学习在给定相机图像的条件下，通过掩码自编码器的方式来重建被遮蔽的触觉图像。
 * 这种预训练迫使模型学习一个联合的视觉-触觉表征，该表征具有以下特点：
   * 可解释性： 能够持续关注与物理交互相关的接触区域。
   * 互补性： 视觉提供全局信息，触觉提供局部、高分辨率的接触和力信息。
 * 下游任务应用： 预训练的表征随后与机器人本体感觉状态结合，作为模仿学习策略的输入，用于执行下游精细操作任务

 ## 数据
提供了一个大规模的 "Touch in the Wild" 数据集，包含：
 * 四项核心任务：
   * 试管插入：精确地将试管插入狭窄的孔洞。
   * 移液管液体转移：需要精确的力量控制来吸取和释放液体。
   * 白板擦除：需要适当的接触压力来擦除文字。
   * 铅笔抓取与调整 。
 * 室内任务： 额外的精细任务，通常在实验室环境中收集。
 * 野外数据： 在多样化的现实世界地点（非实验室）收集的各种交互数据，用于验证模型的泛化性和鲁棒性。